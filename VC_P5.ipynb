{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:45:36.593621: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-14 15:45:36.597797: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-14 15:45:36.608344: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731599136.627183    5361 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731599136.632185    5361 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-14 15:45:36.650768: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-14 15:45:39.415003: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-11-14 15:45:39.681974: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2024-11-14 15:45:39.785480: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2024-11-14 15:45:39.893500: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2024-11-14 15:45:40.827435: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "QApplication: invalid style override 'adwaita' passed, ignoring it.\n",
      "\tAvailable styles: Windows, Fusion\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "import numpy as np\n",
    "\n",
    "# Configuración de captura de video y máscara\n",
    "vid = cv2.VideoCapture(0)\n",
    "mascara = cv2.imread(\"careta.png\", cv2.IMREAD_UNCHANGED)\n",
    "scaleFactor = 1\n",
    "\n",
    "while True:      \n",
    "    # Captura fotograma a fotograma\n",
    "    ret, frame = vid.read()\n",
    "  \n",
    "    if ret:  \n",
    "        obj = DeepFace.analyze(img_path=frame, enforce_detection=False, actions=['gender'])\n",
    "\n",
    "        # Comprobar si se detecta una cara con suficiente confianza\n",
    "        if (obj[0][\"face_confidence\"] > 0.5):\n",
    "            landmarks = obj[0]['region']\n",
    "            x, y, w, h = landmarks[\"x\"], landmarks[\"y\"], landmarks[\"w\"], landmarks[\"h\"]\n",
    "            \n",
    "            # Obtener la posición de los ojos, puede ser que no detecte\n",
    "            if (landmarks[\"left_eye\"]):\n",
    "                eye_left = landmarks[\"left_eye\"]\n",
    "                eye_left_x = eye_left[0]\n",
    "                eye_left_y = eye_left[1]\n",
    "            if (landmarks[\"right_eye\"]):\n",
    "                eye_right = landmarks[\"right_eye\"]\n",
    "                eye_right_x = eye_right[0]\n",
    "                eye_right_y = eye_right[1]\n",
    "            else:\n",
    "                x, y, w, h = landmarks[\"x\"], landmarks[\"y\"], landmarks[\"w\"], landmarks[\"h\"]\n",
    "            \n",
    "                resized = cv2.resize(mascara, (int(w*scaleFactor), int(h*scaleFactor)))\n",
    "                W, H = resized.shape[:2]\n",
    "                \n",
    "                overlay_rgb = resized[:, :, :3]  # Canales de color\n",
    "                alpha_mask = resized[:, :, 3] / 255.0  # Normalizar canal alfa\n",
    "\n",
    "                frame[y:y+H, x:x+W] = (1.0 - alpha_mask[..., None]) * frame[y:y+H, x:x+W] + alpha_mask[..., None] * overlay_rgb    \n",
    "                continue\n",
    "            \n",
    "            # Calcular el ángulo de rotación con en la diferencia de altura de los ojos\n",
    "            delta_x = eye_left_x - eye_right_x\n",
    "            delta_y = eye_left_y - eye_right_y\n",
    "\n",
    "            angle = -np.degrees(np.arctan2(delta_y, delta_x))\n",
    "\n",
    "            # Redimensionar la máscara\n",
    "            resized = cv2.resize(mascara, (int(w * scaleFactor), int(h * scaleFactor)))\n",
    "            \n",
    "            # Rotar la máscara según el ángulo calculado\n",
    "            (h_masc, w_masc) = resized.shape[:2]\n",
    "            center = (w_masc // 2, h_masc // 2)\n",
    "            rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "            rotated_mask = cv2.warpAffine(resized, rotation_matrix, (w_masc, h_masc), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0, 0))\n",
    "\n",
    "            # Separar canales de color y alfa de la máscara rotada\n",
    "            overlay_rgb = rotated_mask[:, :, :3]  # Canales de color\n",
    "            alpha_mask = rotated_mask[:, :, 3] / 255.0  # Normalizar canal alfa\n",
    "\n",
    "            # Superponer la máscara rotada sobre el frame\n",
    "            \n",
    "            frame[y:y+h_masc, x:x+w_masc] = (1.0 - alpha_mask[..., None]) * frame[y:y+h_masc, x:x+w_masc] + alpha_mask[..., None] * overlay_rgb\n",
    "                    \n",
    "        # Mostrar el fotograma resultante\n",
    "        cv2.imshow('Vid', frame)\n",
    "    \n",
    "    # Detenemos pulsado ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "\n",
    "# Libera el objeto de captura y destruye ventanas\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
